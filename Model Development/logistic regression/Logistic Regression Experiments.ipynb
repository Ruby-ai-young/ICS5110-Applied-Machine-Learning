{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d21c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T20:34:35.116935800Z",
     "start_time": "2023-12-05T20:34:34.644522800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d36295",
   "metadata": {},
   "source": [
    "## 20 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8083b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 1.0\n",
      "Recall: 0.6\n",
      "F1 Score: 0.7499999999999999\n",
      "Confusion Matrix: \n",
      " [[0 0]\n",
      " [2 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.00      0.00      0.00         0\n",
      "1 - Released       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.30      0.37         5\n",
      "weighted avg       1.00      0.60      0.75         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_20.csv')\n",
    "data.head()\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "#Hyper parameter tuning\n",
    "#Changing the C variable made no effect\n",
    "#n_jobs = -1, solver = 'sag' - did a little worse\n",
    "# n_jobs = -1, solver = 'saga' - did a little worse\n",
    "# n_jobs = -1, solver = 'saga', random_state = 42\n",
    "\n",
    "\n",
    "lr_model.fit(x_train, y_train)\n",
    "y_pred = lr_model.predict(x_test)\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))\n",
    "\n",
    "# disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'cool')\n",
    "# #disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11ce17",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb1f1446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 1.0\n",
      "Recall: 0.6\n",
      "F1 Score: 0.7499999999999999\n",
      "Confusion Matrix: \n",
      " [[0 0]\n",
      " [2 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.00      0.00      0.00         0\n",
      "1 - Released       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.30      0.37         5\n",
      "weighted avg       1.00      0.60      0.75         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_20.csv')\n",
    "data.head()\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#drop only release so PCA does the work\n",
    "x = data.drop(columns = ['release'], axis = 1) \n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()  #n_components=0.95 Retain 95% of variance\n",
    "#Hyperparameter Tuning \n",
    "#Random state - no effect\n",
    "#n_components - numbers made little different. When flaots the model does badly >0.5\n",
    "\n",
    "X_train_pca = pca.fit_transform(x_train)\n",
    "X_test_pca = pca.transform(x_test)\n",
    "\n",
    "# # Print the explained variance ratio of each principal component\n",
    "# print(\"Explained Variance Ratio per Principal Component:\")\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# # Print the number of components\n",
    "# print(f\"Number of Principal Components: {pca.n_components_}\")\n",
    "\n",
    "# # Print the PCA components\n",
    "# print(\"\\nPCA Components (Linear Combinations of Original Features):\")\n",
    "# print(pca.components_)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "pca_lr_model = LogisticRegression(max_iter = 1000)\n",
    "#random state - no effect\n",
    "\n",
    "# Train the model\n",
    "pca_lr_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = pca_lr_model.predict(X_test_pca)\n",
    "\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8508acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T20:34:36.670037500Z",
     "start_time": "2023-12-05T20:34:36.538098100Z"
    }
   },
   "source": [
    "# 300k data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e447d3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T20:34:35.928555600Z",
     "start_time": "2023-12-05T20:34:35.487130400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>new_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>judge_id</th>\n",
       "      <th>case_type</th>\n",
       "      <th>offence_category</th>\n",
       "      <th>age_offense</th>\n",
       "      <th>age_judge</th>\n",
       "      <th>prior_felony</th>\n",
       "      <th>prior_misdemeanor</th>\n",
       "      <th>prior_criminal_traffic</th>\n",
       "      <th>highest_severity</th>\n",
       "      <th>release</th>\n",
       "      <th>probation</th>\n",
       "      <th>med_house_income</th>\n",
       "      <th>year</th>\n",
       "      <th>jail</th>\n",
       "      <th>violent_crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>153765</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69902.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>889245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26297.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>650004</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57278.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>868753</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49393.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>318360</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1581</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34239.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  new_id  sex  race  judge_id  case_type  offence_category  \\\n",
       "0      13  153765    1     3      1106          0                31   \n",
       "1      44  889245    0     1      1013          0                31   \n",
       "2      59  650004    1     3       517          0                35   \n",
       "3      56  868753    0     3       456          1                39   \n",
       "4      40  318360    1     0      1581          2                63   \n",
       "\n",
       "   age_offense  age_judge  prior_felony  prior_misdemeanor  \\\n",
       "0           20         20             0                  2   \n",
       "1           18         19             1                  0   \n",
       "2           32         33             2                  0   \n",
       "3           19         20             4                  3   \n",
       "4           37         37             0                  0   \n",
       "\n",
       "   prior_criminal_traffic  highest_severity  release  probation  \\\n",
       "0                       0               7.0        1        0.0   \n",
       "1                       3               7.0        0        0.0   \n",
       "2                       0               7.0        0        0.0   \n",
       "3                       0              12.0        1        1.0   \n",
       "4                       0               7.0        1        0.0   \n",
       "\n",
       "   med_house_income  year  jail  violent_crime  \n",
       "0           69902.0  2005   0.0              0  \n",
       "1           26297.0  2008   8.0              0  \n",
       "2           57278.0  2001  45.0              0  \n",
       "3           49393.0  2013   0.0              0  \n",
       "4           34239.0  2004  30.0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_300k.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4a38ec75dc5fe",
   "metadata": {},
   "source": [
    "## Base Model - No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051f5978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8121866666666666\n",
      "Precision: 0.8008003106691205\n",
      "Recall: 0.9539795241064425\n",
      "F1 Score: 0.8707042150095462\n",
      "ROC AUC: 0.7436709312182729\n",
      "Log Loss: 6.7694786885213905\n",
      "Confusion Matrix: \n",
      " [[13485 11798]\n",
      " [ 2288 47429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.85      0.53      0.66     25283\n",
      "1 - Released       0.80      0.95      0.87     49717\n",
      "\n",
      "    accuracy                           0.81     75000\n",
      "   macro avg       0.83      0.74      0.76     75000\n",
      "weighted avg       0.82      0.81      0.80     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_300k.csv')\n",
    "data.head()\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "#Hyper parameter tuning\n",
    "#Changing the C variable made no effect\n",
    "#n_jobs = -1, solver = 'sag' - did a little worse\n",
    "# n_jobs = -1, solver = 'saga' - did a little worse\n",
    "# n_jobs = -1, solver = 'saga', random_state = 42\n",
    "\n",
    "\n",
    "lr_model.fit(x_train, y_train)\n",
    "y_pred = lr_model.predict(x_test)\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))\n",
    "\n",
    "# disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'cool')\n",
    "# #disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a19119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7922\n",
      "Precision: 0.7794223590280961\n",
      "Recall: 0.9574994468692801\n",
      "F1 Score: 0.8593322682840975\n",
      "Confusion Matrix: \n",
      " [[11811 13472]\n",
      " [ 2113 47604]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.85      0.47      0.60     25283\n",
      "1 - Released       0.78      0.96      0.86     49717\n",
      "\n",
      "    accuracy                           0.79     75000\n",
      "   macro avg       0.81      0.71      0.73     75000\n",
      "weighted avg       0.80      0.79      0.77     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_300k.csv')\n",
    "data.head()\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 10000, C = 1.0, solver = 'saga', n_jobs = -1, penalty = 'l1', random_state = 0) #default max iter does not converge\n",
    "\n",
    "#Hyper parameter tuning\n",
    "#Changing the C variable made no effect\n",
    "#n_jobs = -1, solver = 'sag' - did a little worse\n",
    "# n_jobs = -1, solver = 'saga' - did a little worse\n",
    "# n_jobs = -1, solver = 'saga', random_state = 42\n",
    "\n",
    "\n",
    "lr_model.fit(x_train, y_train)\n",
    "y_pred = lr_model.predict(x_test)\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))\n",
    "\n",
    "# disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'cool')\n",
    "# #disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90015a8",
   "metadata": {},
   "source": [
    "## Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e926636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Principal Components: 18\n",
      "Accuracy: 0.75744\n",
      "Precision: 0.7401538813133237\n",
      "Recall: 0.9771305589637347\n",
      "F1 Score: 0.8422914210416812\n",
      "Confusion Matrix: \n",
      " [[ 8228 17055]\n",
      " [ 1137 48580]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.88      0.33      0.47     25283\n",
      "1 - Released       0.74      0.98      0.84     49717\n",
      "\n",
      "    accuracy                           0.76     75000\n",
      "   macro avg       0.81      0.65      0.66     75000\n",
      "weighted avg       0.79      0.76      0.72     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_300k.csv')\n",
    "data.head()\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#drop only release so PCA does the work\n",
    "x = data.drop(columns = ['release'], axis = 1) \n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()  #n_components=0.95 Retain 95% of variance\n",
    "#Hyperparameter Tuning \n",
    "#Random state - no effect\n",
    "#n_components - numbers made little different. When flaots the model does badly >0.5\n",
    "\n",
    "X_train_pca = pca.fit_transform(x_train)\n",
    "X_test_pca = pca.transform(x_test)\n",
    "\n",
    "# # Print the explained variance ratio of each principal component\n",
    "# print(\"Explained Variance Ratio per Principal Component:\")\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Print the number of components\n",
    "print(f\"Number of Principal Components: {pca.n_components_}\")\n",
    "\n",
    "# # Print the PCA components\n",
    "# print(\"\\nPCA Components (Linear Combinations of Original Features):\")\n",
    "# print(pca.components_)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "pca_lr_model = LogisticRegression(max_iter = 1000)\n",
    "#random state - no effect\n",
    "\n",
    "# Train the model\n",
    "pca_lr_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = pca_lr_model.predict(X_test_pca)\n",
    "\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf0dc7",
   "metadata": {},
   "source": [
    "# 500k data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1bd812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>new_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>judge_id</th>\n",
       "      <th>case_type</th>\n",
       "      <th>offence_category</th>\n",
       "      <th>age_offense</th>\n",
       "      <th>age_judge</th>\n",
       "      <th>prior_felony</th>\n",
       "      <th>prior_misdemeanor</th>\n",
       "      <th>prior_criminal_traffic</th>\n",
       "      <th>highest_severity</th>\n",
       "      <th>release</th>\n",
       "      <th>probation</th>\n",
       "      <th>med_house_income</th>\n",
       "      <th>year</th>\n",
       "      <th>jail</th>\n",
       "      <th>violent_crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>369136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>978</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62350.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90240</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>322</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47081.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>930588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1447</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41351.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>275737</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1058</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54555.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>579161</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1027</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47081.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  new_id  sex  race  judge_id  case_type  offence_category  \\\n",
       "0      30  369136    1     0       978          2                49   \n",
       "1       1   90240    1     3       322          2                16   \n",
       "2      27  930588    1     1      1447          2                 5   \n",
       "3      44  275737    0     3      1058          1                55   \n",
       "4      41  579161    1     3      1027          2                64   \n",
       "\n",
       "   age_offense  age_judge  prior_felony  prior_misdemeanor  \\\n",
       "0           39         40             3                  2   \n",
       "1           18         18             1                  0   \n",
       "2           25         27             3                  6   \n",
       "3           49         49             0                  0   \n",
       "4           17         17             0                  2   \n",
       "\n",
       "   prior_criminal_traffic  highest_severity  release  probation  \\\n",
       "0                       0              10.0        1        1.0   \n",
       "1                       0               7.0        1        1.0   \n",
       "2                       9              10.0        0        0.0   \n",
       "3                       0              10.0        1        1.0   \n",
       "4                       0              10.0        1        1.0   \n",
       "\n",
       "   med_house_income  year  jail  violent_crime  \n",
       "0           62350.0  2014   0.0              0  \n",
       "1           47081.0  2002   0.0              0  \n",
       "2           41351.0  2007  30.0              0  \n",
       "3           54555.0  2007   0.0              0  \n",
       "4           47081.0  2007   0.0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_500k.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6289d",
   "metadata": {},
   "source": [
    "## No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f46b06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811512\n",
      "Precision: 0.7990645197292991\n",
      "Recall: 0.9544672290091138\n",
      "F1 Score: 0.8698797709185899\n",
      "ROC AUC: 0.7441795757171346\n",
      "Log Loss: 6.793796140007913\n",
      "Confusion Matrix: \n",
      " [[22684 19804]\n",
      " [ 3757 78755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.86      0.53      0.66     42488\n",
      "1 - Released       0.80      0.95      0.87     82512\n",
      "\n",
      "    accuracy                           0.81    125000\n",
      "   macro avg       0.83      0.74      0.76    125000\n",
      "weighted avg       0.82      0.81      0.80    125000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "#base model (using the default parameters)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "lr_model.fit(x_train, y_train)\n",
    "y_pred = lr_model.predict(x_test)\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'ROC AUC: {auc}')\n",
    "print(f'Log Loss: {logloss}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'cool')\n",
    "#disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c565b85",
   "metadata": {},
   "source": [
    "## Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d2268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756264\n",
      "Precision: 0.7380680102829645\n",
      "Recall: 0.9777486910994765\n",
      "F1 Score: 0.8411679760607657\n",
      "ROC AUC: 0.6519439181349388\n",
      "Log Loss: 8.785135902449857\n",
      "Confusion Matrix: \n",
      " [[13857 28631]\n",
      " [ 1836 80676]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.88      0.33      0.48     42488\n",
      "1 - Released       0.74      0.98      0.84     82512\n",
      "\n",
      "    accuracy                           0.76    125000\n",
      "   macro avg       0.81      0.65      0.66    125000\n",
      "weighted avg       0.79      0.76      0.72    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#drop only release so PCA does the work\n",
    "x = data.drop(columns = ['release'], axis = 1) \n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()  #n_components=0.95 Retain 95% of variance\n",
    "X_train_pca = pca.fit_transform(x_train)\n",
    "X_test_pca = pca.transform(x_test)\n",
    "\n",
    "# # Print the explained variance ratio of each principal component\n",
    "# print(\"Explained Variance Ratio per Principal Component:\")\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# # Print the number of components\n",
    "# print(f\"Number of Principal Components: {pca.n_components_}\")\n",
    "\n",
    "# # Print the PCA components\n",
    "# print(\"\\nPCA Components (Linear Combinations of Original Features):\")\n",
    "# print(pca.components_)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "pca_lr_model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# Train the model\n",
    "pca_lr_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = pca_lr_model.predict(X_test_pca)\n",
    "\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'ROC AUC: {auc}')\n",
    "print(f'Log Loss: {logloss}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe31e7",
   "metadata": {},
   "source": [
    "# Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b37d275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>new_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>judge_id</th>\n",
       "      <th>case_type</th>\n",
       "      <th>offence_category</th>\n",
       "      <th>age_offense</th>\n",
       "      <th>age_judge</th>\n",
       "      <th>prior_felony</th>\n",
       "      <th>prior_misdemeanor</th>\n",
       "      <th>prior_criminal_traffic</th>\n",
       "      <th>highest_severity</th>\n",
       "      <th>release</th>\n",
       "      <th>probation</th>\n",
       "      <th>med_house_income</th>\n",
       "      <th>year</th>\n",
       "      <th>jail</th>\n",
       "      <th>violent_crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34942.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67610.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45428.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45428.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  new_id  sex  race  judge_id  case_type  offence_category  \\\n",
       "0      40       3    1     0       436          1                16   \n",
       "1      30       6    1     3      1049          2                13   \n",
       "2      30       7    1     0      1009          2                49   \n",
       "3      30      12    1     3       232          0                35   \n",
       "4      40      17    1     0       694          0                31   \n",
       "\n",
       "   age_offense  age_judge  prior_felony  prior_misdemeanor  \\\n",
       "0           40         41             0                  0   \n",
       "1           39         40             0                  0   \n",
       "2           17         17             0                  0   \n",
       "3           65         65             0                  0   \n",
       "4           51         51             1                  0   \n",
       "\n",
       "   prior_criminal_traffic  highest_severity  release  probation  \\\n",
       "0                       0               7.0        1        0.0   \n",
       "1                       0               9.0        1        1.0   \n",
       "2                       0               9.0        1        1.0   \n",
       "3                       0               7.0        0        0.0   \n",
       "4                       0               7.0        1        0.0   \n",
       "\n",
       "   med_house_income  year  jail  violent_crime  \n",
       "0           34942.0  2012   9.0              0  \n",
       "1           67610.0  2000   0.0              0  \n",
       "2           45428.0  2000   0.0              0  \n",
       "3           45428.0  2000  20.0              0  \n",
       "4           22838.0  2001   0.0              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('modified_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "521965e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8112218685354377\n",
      "Precision: 0.7992304217854077\n",
      "Recall: 0.9538427352818939\n",
      "F1 Score: 0.8697185608746713\n",
      "ROC AUC: 0.7437330036317843\n",
      "Log Loss: 6.8042535379538736\n",
      "Confusion Matrix: \n",
      " [[ 66625  58229]\n",
      " [ 11217 231800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.86      0.53      0.66    124854\n",
      "1 - Released       0.80      0.95      0.87    243017\n",
      "\n",
      "    accuracy                           0.81    367871\n",
      "   macro avg       0.83      0.74      0.76    367871\n",
      "weighted avg       0.82      0.81      0.80    367871\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "#base model (using the default parameters)\n",
    "lr_model = LogisticRegression(max_iter = 2000) #default max iter does not converge neither does 1k\n",
    "lr_model.fit(x_train, y_train)\n",
    "y_pred = lr_model.predict(x_test)\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'ROC AUC: {auc}')\n",
    "print(f'Log Loss: {logloss}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'cool')\n",
    "#disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ccd4cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7617153839253434\n",
      "Precision: 0.7437164487699581\n",
      "Recall: 0.9754214725718777\n",
      "F1 Score: 0.8439543850779534\n",
      "ROC AUC: 0.6605886576981483\n",
      "Log Loss: 8.588648109753773\n",
      "Confusion Matrix: \n",
      " [[ 43169  81685]\n",
      " [  5973 237044]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0 - Detained       0.88      0.35      0.50    124854\n",
      "1 - Released       0.74      0.98      0.84    243017\n",
      "\n",
      "    accuracy                           0.76    367871\n",
      "   macro avg       0.81      0.66      0.67    367871\n",
      "weighted avg       0.79      0.76      0.73    367871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#drop only release so PCA does the work\n",
    "x = data.drop(columns = ['release'], axis = 1) \n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()  #n_components=0.95 Retain 95% of variance\n",
    "X_train_pca = pca.fit_transform(x_train)\n",
    "X_test_pca = pca.transform(x_test)\n",
    "\n",
    "# # Print the explained variance ratio of each principal component\n",
    "# print(\"Explained Variance Ratio per Principal Component:\")\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# # Print the number of components\n",
    "# print(f\"Number of Principal Components: {pca.n_components_}\")\n",
    "\n",
    "# # Print the PCA components\n",
    "# print(\"\\nPCA Components (Linear Combinations of Original Features):\")\n",
    "# print(pca.components_)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "pca_lr_model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# Train the model\n",
    "pca_lr_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = pca_lr_model.predict(X_test_pca)\n",
    "\n",
    "\n",
    "#evaluation \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1score}')\n",
    "print(f'ROC AUC: {auc}')\n",
    "print(f'Log Loss: {logloss}')\n",
    "print(f'Confusion Matrix: \\n {conf_matrix}')\n",
    "print(classification_report(y_test, y_pred, target_names=['0 - Detained', '1 - Released']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bef367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_300k.csv')\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "params = {'penalty': ['l1', 'l2', 'elasticent'],\n",
    "          'C': [1.0, 0.5, 0.25, 0.1, 0.75],\n",
    "          'random_state': [0, 1, 5, 10, 20, 100],\n",
    "          'solver': ['lbfgs', 'sag', 'saga'], # ‘liblinear’, ‘newton-cg’, ‘newton-cholesky' ccaused warning that they dont convierge, etc\n",
    "          'max_iter': [10000, 100, 1000, 500],\n",
    "          'n_jobs': ['none', -1] #none means 1\n",
    "          }\n",
    "\n",
    "gsLR = GridSearchCV(lr_model, params, scoring = 'accuracy')\n",
    "gsLR.fit(x_train, y_train)\n",
    "\n",
    "print(gsLR.best_params_)\n",
    "print(gsLR.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824a5574daa4c97",
   "metadata": {},
   "source": [
    "## GridSearchCV Using 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c124a33b26145e25",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T21:01:04.198659100Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l1', 'random_state': 0, 'solver': 'saga'}\n",
      "0.8666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "8400 fits failed out of a total of 10800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LogisticRegression must be None or an instance of 'int'. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'elasticent' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_20.csv')\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "params = {'penalty': ['l1', 'l2', 'elasticent'],\n",
    "          'C': [1.0, 0.5, 0.25, 0.1, 0.75],\n",
    "          'random_state': [0, 1, 5, 10, 20, 100],\n",
    "          'solver': ['lbfgs', 'sag', 'saga'], # ‘liblinear’, ‘newton-cg’, ‘newton-cholesky' ccaused warning that they dont convierge, etc\n",
    "          'max_iter': [10000, 100, 1000, 500],\n",
    "          'n_jobs': ['none', -1] #none means 1\n",
    "          }\n",
    "\n",
    "gsLR = GridSearchCV(lr_model, params, scoring = 'accuracy')\n",
    "gsLR.fit(x_train, y_train)\n",
    "\n",
    "print(gsLR.best_params_)\n",
    "print(gsLR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5917380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 100, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "0.9333333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "8400 fits failed out of a total of 10800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LogisticRegression must be None or an instance of 'int'. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'elasticent' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_20.csv')\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "params = {'penalty': ['l1', 'l2', 'elasticent'],\n",
    "          'C': [1.0, 0.5, 0.25, 0.1, 0.75],\n",
    "          'random_state': [0, 1, 5, 10, 20, 100],\n",
    "          'solver': ['lbfgs', 'sag', 'saga'], # ‘liblinear’, ‘newton-cg’, ‘newton-cholesky' ccaused warning that they dont convierge, etc\n",
    "          'max_iter': [10000, 100, 1000, 500],\n",
    "          'n_jobs': ['none', -1] #none means 1\n",
    "          }\n",
    "\n",
    "gsLR = GridSearchCV(lr_model, params, scoring = 'precision')\n",
    "gsLR.fit(x_train, y_train)\n",
    "\n",
    "print(gsLR.best_params_)\n",
    "print(gsLR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "828131b82eab0a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T20:34:47.159153800Z",
     "start_time": "2023-12-05T20:34:47.127481500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 100, 'n_jobs': -1, 'penalty': 'l1', 'random_state': 0, 'solver': 'saga'}\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "8400 fits failed out of a total of 10800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LogisticRegression must be None or an instance of 'int'. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'elasticent' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_20.csv')\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "params = {'penalty': ['l1', 'l2', 'elasticent'],\n",
    "          'C': [1.0, 0.5, 0.25, 0.1, 0.75],\n",
    "          'random_state': [0, 1, 5, 10, 20, 100],\n",
    "          'solver': ['lbfgs', 'sag', 'saga'], # ‘liblinear’, ‘newton-cg’, ‘newton-cholesky' ccaused warning that they dont convierge, etc\n",
    "          'max_iter': [10000, 100, 1000, 500],\n",
    "          'n_jobs': ['none', -1] #none means 1\n",
    "          }\n",
    "\n",
    "gsLR = GridSearchCV(lr_model, params, scoring = 'recall')\n",
    "gsLR.fit(x_train, y_train)\n",
    "\n",
    "print(gsLR.best_params_)\n",
    "print(gsLR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa78110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l1', 'random_state': 0, 'solver': 'saga'}\n",
      "0.9199999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "8400 fits failed out of a total of 10800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LogisticRegression must be None or an instance of 'int'. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'elasticent' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_20.csv')\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "params = {'penalty': ['l1', 'l2', 'elasticent'],\n",
    "          'C': [1.0, 0.5, 0.25, 0.1, 0.75],\n",
    "          'random_state': [0, 1, 5, 10, 20, 100],\n",
    "          'solver': ['lbfgs', 'sag', 'saga'], # ‘liblinear’, ‘newton-cg’, ‘newton-cholesky' ccaused warning that they dont convierge, etc\n",
    "          'max_iter': [10000, 100, 1000, 500],\n",
    "          'n_jobs': ['none', -1] #none means 1\n",
    "          }\n",
    "\n",
    "gsLR = GridSearchCV(lr_model, params, scoring = 'f1')\n",
    "gsLR.fit(x_train, y_train)\n",
    "\n",
    "print(gsLR.best_params_)\n",
    "print(gsLR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5011d17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l1', 'random_state': 0, 'solver': 'saga'}\n",
      "0.8666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "8400 fits failed out of a total of 10800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LogisticRegression must be None or an instance of 'int'. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'elasticent' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\vella\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "data = pd.read_csv('sampled_file_20.csv')\n",
    "\n",
    "#predicting whether the released or not (0 -> detained, 1-> released) \n",
    "#split dataset in features and target variable\n",
    "x = data.drop(columns = ['new_id', 'release', 'probation', 'med_house_income', 'year'], axis = 1) #features\n",
    "y = data['release'].values #target variable\n",
    "\n",
    "#split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#base model (using the default parametnewton-cholesky’ers)\n",
    "lr_model = LogisticRegression(max_iter = 1000) #default max iter does not converge\n",
    "\n",
    "params = {'penalty': ['l1', 'l2', 'elasticent'],\n",
    "          'C': [1.0, 0.5, 0.25, 0.1, 0.75],\n",
    "          'random_state': [0, 1, 5, 10, 20, 100],\n",
    "          'solver': ['lbfgs', 'sag', 'saga'], # ‘liblinear’, ‘newton-cg’, ‘newton-cholesky' ccaused warning that they dont convierge, etc\n",
    "          'max_iter': [10000, 100, 1000, 500],\n",
    "          'n_jobs': ['none', -1] #none means 1\n",
    "          }\n",
    "\n",
    "gsLR = GridSearchCV(lr_model, params)\n",
    "gsLR.fit(x_train, y_train)\n",
    "\n",
    "print(gsLR.best_params_)\n",
    "print(gsLR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dba6b7e590a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
